{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "fb4de038-ce88-411e-884a-c305dfd0a8c3",
      "metadata": {
        "id": "fb4de038-ce88-411e-884a-c305dfd0a8c3"
      },
      "source": [
        "# Question-Answering Chatbot via Transformer\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-danger\">\n",
        "<b>Google Colab:</b> This notebook tutorial will not work through Google Colab, or most similar hosted notebook services, since it requires you to expose a port on your machine.\n",
        "    To follow along with this tutorial, please download the notebook and run it in you local Jupyter environment.\n",
        "</div>\n",
        "\n",
        "In this tutorial, you will build your own chatbot that can answer questions about COVID-19 through a web interface.\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>See Also:</b> In this tutorial you will recreate Jina's chatbot example: https://docs.jina.ai/get-started/hello-world/covid-19-chatbot/.\n",
        "The code here has some minor changes compared to the originial source, which you can find [here](https://github.com/jina-ai/jina/tree/master/jina/helloworld/chatbot).</div>\n",
        "\n",
        "At the end of this tutorial, you will have your own chatbot. You will use text as an input and get a text results as\n",
        "output. For this example, we will use a [covid dataset](https://www.kaggle.com/xhlulu/covidqa). You will understand how\n",
        "every part of this example works and how you can create new apps with different datasets on your own."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d0afce7e-e57a-4e61-9a12-235e98c77876",
      "metadata": {
        "id": "d0afce7e-e57a-4e61-9a12-235e98c77876"
      },
      "source": [
        "## Define data and work directories\n",
        "\n",
        "You can start by creating an empty folder.\n",
        "Here, that folder is simply named 'tutorial', but you can name it whatever you want.\n",
        "\n",
        "The chatbot will disply its answers in a browser, so download the static folder from\n",
        "[here](https://github.com/jina-ai/jina/tree/master/jina/helloworld/chatbot/static), or by simply running the next cell.\n",
        "This is only the CSS and HTML files to render our results."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e740b6d9-f8c3-4e7f-974f-ff91b0ea4d5b",
      "metadata": {
        "id": "e740b6d9-f8c3-4e7f-974f-ff91b0ea4d5b"
      },
      "outputs": [],
      "source": [
        "! wget --directory-prefix=./static https://raw.githubusercontent.com/jina-ai/jina/master/jina/helloworld/chatbot/static/index.html https://raw.githubusercontent.com/jina-ai/jina/master/jina/helloworld/chatbot/static/script.js https://raw.githubusercontent.com/jina-ai/jina/master/jina/helloworld/chatbot/static/style.css https://raw.githubusercontent.com/jina-ai/jina/master/jina/helloworld/chatbot/static/license.txt"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "6912d093-341b-4f17-af9c-bb44ae20d224",
      "metadata": {
        "id": "6912d093-341b-4f17-af9c-bb44ae20d224"
      },
      "source": [
        "The bot uses a dataset in a `.csv` format. In this tutorial you will use\n",
        "the [COVID](https://www.kaggle.com/xhlulu/covidqa) dataset from Kaggle.\n",
        "\n",
        "Download it under your `tutorial` directory:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9169b9f5-997d-49d1-92ce-e49376d3ff33",
      "metadata": {
        "id": "9169b9f5-997d-49d1-92ce-e49376d3ff33"
      },
      "outputs": [],
      "source": [
        "! wget https://static.jina.ai/chatbot/dataset.csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e22fb898-cd2b-4623-8f1d-6ed1090d4831",
      "metadata": {
        "id": "e22fb898-cd2b-4623-8f1d-6ed1090d4831"
      },
      "source": [
        "## Create Documents from a csv file\n",
        "\n",
        "In the most simple case, a `Document` can be created like this:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3343a6a7-6915-4478-a27f-b32a1a206cce",
      "metadata": {
        "id": "3343a6a7-6915-4478-a27f-b32a1a206cce"
      },
      "outputs": [],
      "source": [
        "from docarray import Document\n",
        "\n",
        "doc = Document(content='hello, world!')"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "f0ed7247-7521-428d-97ba-cb7b37b8106b",
      "metadata": {
        "id": "f0ed7247-7521-428d-97ba-cb7b37b8106b"
      },
      "source": [
        "In the case of your chatbot, the content of the Documents needs to be the dataset we want to use.\n",
        "Additionally, if the dataset at hand is large compared to the available system memory, it makes sense to pass the Documents\n",
        "as a *generator*"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6b208c2e-a3b5-4084-9b08-bfec70fe1ec2",
      "metadata": {
        "id": "6b208c2e-a3b5-4084-9b08-bfec70fe1ec2"
      },
      "outputs": [],
      "source": [
        "from docarray import Document, DocumentArray\n",
        "from docarray.document.generators import from_csv\n",
        "\n",
        "docs = from_csv('dataset.csv', field_resolver={'question': 'text'})"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "50a45a75-1bb6-415e-8d4d-a7e3e78c2009",
      "metadata": {
        "id": "50a45a75-1bb6-415e-8d4d-a7e3e78c2009"
      },
      "source": [
        "So what happened there? You created a generator of Documents `docs`, and you\n",
        "used [from_csv](https://docarray.jina.ai/api/docarray.document.generators/?highlight=generators#module-docarray.document.generators) to\n",
        "load our dataset. You used `field_resolver` to map the text from our dataset to the Document attributes.\n",
        "\n",
        "## Create Flow\n",
        "\n",
        "No you need to create a simple `Flow` that processes the Documents.\n",
        "\n",
        "For now, your Flow will be little more than a placeholder pipeline.\n",
        "You will add actual functionality later in this tutorial.\n",
        "\n",
        "First, you should import everything we need:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1553cf93-a707-49b2-a1ba-ca1d8e9007cf",
      "metadata": {
        "id": "1553cf93-a707-49b2-a1ba-ca1d8e9007cf"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import webbrowser\n",
        "from pathlib import Path\n",
        "from jina import Flow, Executor, requests\n",
        "from jina.logging.predefined import default_logger\n",
        "from docarray.document.generators import from_csv"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3e2bbc40-31a1-41d0-93b1-389177a14d12",
      "metadata": {
        "id": "3e2bbc40-31a1-41d0-93b1-389177a14d12"
      },
      "source": [
        "Then you can create a `main` and a `tutorial` function that creates a Flow and two dummy Executors."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "e33b1cc5-fcdf-4304-8b90-857bfec8ccc5",
      "metadata": {
        "id": "e33b1cc5-fcdf-4304-8b90-857bfec8ccc5"
      },
      "outputs": [],
      "source": [
        "def tutorial(port_expose):\n",
        "    class MyTransformer(Executor):\n",
        "        @requests(on='/foo')\n",
        "        def foo(self, **kwargs):\n",
        "            print(f'foo is doing cool stuff: {kwargs}')\n",
        "\n",
        "    class MyIndexer(Executor):\n",
        "        @requests(on='/bar')\n",
        "        def bar(self, **kwargs):\n",
        "            print(f'bar is doing cool stuff: {kwargs}')\n",
        "    \n",
        "    flow = (\n",
        "        Flow()\n",
        "            .add(name='MyTransformer', uses=MyTransformer)\n",
        "            .add(name='MyIndexer', uses=MyIndexer)\n",
        "    )\n",
        "    with flow:\n",
        "        flow.index(from_csv('dataset.csv', field_resolver={'question': 'text'}))\n",
        "\n",
        "tutorial(8080)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "97754e3f-d8ed-4694-b7c6-3ddfd1c87588",
      "metadata": {
        "id": "97754e3f-d8ed-4694-b7c6-3ddfd1c87588"
      },
      "source": [
        "If you run this, it should finish without errors. You won't see much yet because we are not showing anything after we\n",
        "index.\n",
        "\n",
        "To actually see something you need to specify how the outputs of the Flow will be displayed.\n",
        "For our tutorial, that will happen through a web browser.\n",
        "After indexing, the program will open a web browser to serve the static html files.\n",
        "\n",
        "You also need to configure and serve the Flow\n",
        "on a specific port with the HTTP protocol so that the web browser can make requests to the Flow. So, you need to pass the\n",
        "parameter `port_expose` to configure the Flow and set the protocol to HTTP. Modify the function `tutorial` like so:\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6147fcd5-1448-4100-b13c-c8188e7cdf13",
      "metadata": {
        "id": "6147fcd5-1448-4100-b13c-c8188e7cdf13"
      },
      "outputs": [],
      "source": [
        "def tutorial(port_expose):\n",
        "    class MyTransformer(Executor):\n",
        "        @requests(on='/foo')\n",
        "        def foo(self, **kwargs):\n",
        "            print(f'foo is doing cool stuff: {kwargs}')\n",
        "    \n",
        "    class MyIndexer(Executor):\n",
        "        @requests(on='/bar')\n",
        "        def bar(self, **kwargs):\n",
        "            print(f'bar is doing cool stuff: {kwargs}')\n",
        "    \n",
        "    flow = (\n",
        "        Flow(cors=True, protocol='http', port_expose = port_expose)\n",
        "            .add(name='MyTransformer', uses=MyTransformer)\n",
        "            .add(name='MyIndexer', uses=MyIndexer)\n",
        "    )\n",
        "    with flow:\n",
        "        flow.index(from_csv('dataset.csv', field_resolver={'question': 'text'}))\n",
        "        url_html_path = 'file://' + os.path.abspath(\n",
        "            os.path.join(\n",
        "                os.path.dirname(os.path.abspath('')), 'static/index.html'\n",
        "            )\n",
        "        )\n",
        "        try:\n",
        "            webbrowser.open(url_html_path, new=2)\n",
        "        except:\n",
        "            pass  # intentional pass, browser support isn't cross-platform\n",
        "        finally:\n",
        "            default_logger.success(\n",
        "                f'You should see a demo page opened in your browser, '\n",
        "                f'if not, you may open {url_html_path} manually'\n",
        "            )\n",
        "        flow.block()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "69229e1c-10bb-478e-b8b6-fc33d3afdd88",
      "metadata": {
        "id": "69229e1c-10bb-478e-b8b6-fc33d3afdd88"
      },
      "source": [
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>See Also:</b> For more information on what the Flow is doing, and how to serve the Flow with 'f.block()' and configure the protocol, \n",
        "check the Flow fundamentals section in the Jina Documentation: https://docs.jina.ai/fundamentals/flow/</div>\n",
        "\n",
        "\n",
        "<div class=\"alert alert-block alert-warning\">\n",
        "<b>Important:</b> Since you want to call your Flow from the browser, it's important to enable \n",
        "Cross-Origin Resource Sharing (https://developer.mozilla.org/en-US/docs/Web/HTTP/CORS) with 'Flow(cors=True)'.\n",
        "</div>\n",
        "\n",
        "Ok, so it seems that you have plenty of work done already. If you run this you will see a new tab open in your browser,\n",
        "and there you will have a text box ready for you to input some text. However, if you try to enter anything you won't get\n",
        "any results. This is because we are using dummy Executors. Our `MyTransformer` and `MyIndexer` aren't actually doing\n",
        "anything. So far they only print a line when they are called. So we need real Executors."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5cd8d961-8e93-453e-b686-19403e6e5cb1",
      "metadata": {
        "id": "5cd8d961-8e93-453e-b686-19403e6e5cb1"
      },
      "source": [
        "## Create Executors\n",
        "\n",
        "It is usuall godd practice to put your Executors in a separate file  (like `my_executors.py`).\n",
        "Here, we will just put everything in the same notebook.\n",
        "\n",
        "### Sentence Transformer\n",
        "\n",
        "First, let's import the following:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "34f6c1e3-4a6e-4c6c-9fe4-f030ea35b52e",
      "metadata": {
        "id": "34f6c1e3-4a6e-4c6c-9fe4-f030ea35b52e"
      },
      "outputs": [],
      "source": [
        "from typing import Dict\n",
        "\n",
        "from docarray import DocumentArray\n",
        "from jina import Executor, requests\n",
        "import numpy as np\n",
        "import torch\n",
        "from transformers import AutoModel, AutoTokenizer"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a80b2c29-5531-4daf-83ca-f528b438a266",
      "metadata": {
        "id": "a80b2c29-5531-4daf-83ca-f528b438a266"
      },
      "source": [
        "Now, let's implement `MyTransformer`:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3830a84e-34c1-43a9-ae1e-bd4166357ff0",
      "metadata": {
        "id": "3830a84e-34c1-43a9-ae1e-bd4166357ff0"
      },
      "outputs": [],
      "source": [
        "class MyTransformer(Executor):\n",
        "    \"\"\"Transformer executor class \"\"\"\n",
        "\n",
        "    def __init__(\n",
        "        self,\n",
        "        pretrained_model_name_or_path: str = 'sentence-transformers/paraphrase-mpnet-base-v2',\n",
        "        pooling_strategy: str = 'mean',\n",
        "        layer_index: int = -1,\n",
        "        *args,\n",
        "        **kwargs,\n",
        "    ):\n",
        "        super().__init__(*args, **kwargs)\n",
        "        self.pretrained_model_name_or_path = pretrained_model_name_or_path\n",
        "        self.pooling_strategy = pooling_strategy\n",
        "        self.layer_index = layer_index\n",
        "        self.tokenizer = AutoTokenizer.from_pretrained(\n",
        "            self.pretrained_model_name_or_path\n",
        "        )\n",
        "        self.model = AutoModel.from_pretrained(\n",
        "            self.pretrained_model_name_or_path, output_hidden_states=True\n",
        "        )\n",
        "        self.model.to(torch.device('cpu'))\n",
        "\n",
        "    def _compute_embedding(self, hidden_states: 'torch.Tensor', input_tokens: Dict):\n",
        "\n",
        "        fill_vals = {'cls': 0.0, 'mean': 0.0, 'max': -np.inf, 'min': np.inf}\n",
        "        fill_val = torch.tensor(\n",
        "            fill_vals[self.pooling_strategy], device=torch.device('cpu')\n",
        "        )\n",
        "\n",
        "        layer = hidden_states[self.layer_index]\n",
        "        attn_mask = input_tokens['attention_mask'].unsqueeze(-1).expand_as(layer)\n",
        "        layer = torch.where(attn_mask.bool(), layer, fill_val)\n",
        "\n",
        "        embeddings = layer.sum(dim=1) / attn_mask.sum(dim=1)\n",
        "        return embeddings.cpu().numpy()\n",
        "\n",
        "    @requests\n",
        "    def encode(self, docs: 'DocumentArray', **kwargs):\n",
        "        with torch.inference_mode():\n",
        "            if not self.tokenizer.pad_token:\n",
        "                self.tokenizer.add_special_tokens({'pad_token': '[PAD]'})\n",
        "                self.model.resize_token_embeddings(len(self.tokenizer.vocab))\n",
        "\n",
        "            input_tokens = self.tokenizer(\n",
        "                docs[:, 'content'],\n",
        "                padding='longest',\n",
        "                truncation=True,\n",
        "                return_tensors='pt',\n",
        "            )\n",
        "            input_tokens = {\n",
        "                k: v.to(torch.device('cpu')) for k, v in input_tokens.items()\n",
        "            }\n",
        "\n",
        "            outputs = self.model(**input_tokens)\n",
        "            hidden_states = outputs.hidden_states\n",
        "\n",
        "            docs.embeddings = self._compute_embedding(hidden_states, input_tokens)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "d3e0ef8d-df33-4887-80f2-b1d872d94c71",
      "metadata": {
        "id": "d3e0ef8d-df33-4887-80f2-b1d872d94c71"
      },
      "source": [
        "`MyTransformer` exposes only one endpoint: `encode`. This will be called whenever you make a request to the Flow, either\n",
        "on query or index. The endpoint will create embeddings for the indexed or query Documents, which in turn can be used to\n",
        "get the closest matches between a question and an answer.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>Note:</b> Encoding is a fundamental concept in neural search. It means representing the data in a vectorial form (embeddings). </div>\n",
        "\n",
        "Encoding is performed through a sentence-transformers model (`paraphrase-mpnet-base-v2` by default). You get the text\n",
        "attributes of docs in batch and then compute embeddings. Later, you will set the embedding attribute of each Document.\n",
        "\n",
        "### Simple Indexer\n",
        "\n",
        "Now, let's implement your indexer (`MyIndexer`):\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>See Also:</b> In order to make this tutorial truly end-to-end, here you implement an Indexer yourself.\n",
        "If you want the same functionality (and slightly more) out of the box, you can also use the\n",
        "SimpleIndexer from Jina Hub: https://hub.jina.ai/executor/zb38xlt4. </div>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9e3e0029-6eb1-4240-97d6-28143bec28bf",
      "metadata": {
        "id": "9e3e0029-6eb1-4240-97d6-28143bec28bf"
      },
      "outputs": [],
      "source": [
        "import os  # imports from above are also needed\n",
        "\n",
        "class MyIndexer(Executor):\n",
        "    \"\"\"Simple indexer class \"\"\"\n",
        "\n",
        "    def __init__(self, **kwargs):\n",
        "        super().__init__(**kwargs)\n",
        "        self.table_name = 'qabot_docs'\n",
        "        self._docs = DocumentArray(storage='sqlite',\n",
        "                                   config={'connection': os.path.join(self.workspace, 'indexer'),\n",
        "                                           'table_name': self.table_name})\n",
        "\n",
        "    @requests(on='/index')\n",
        "    def index(self, docs: 'DocumentArray', **kwargs):\n",
        "        self._docs.extend(docs)\n",
        "\n",
        "    @requests(on='/search')\n",
        "    def search(self, docs: 'DocumentArray', **kwargs):\n",
        "        \"\"\"Append best matches to each document in docs\n",
        "\n",
        "        :param docs: documents that are searched\n",
        "        :param parameters: dictionary of pairs (parameter,value)\n",
        "        :param kwargs: other keyword arguments\n",
        "        \"\"\"\n",
        "        docs.match(\n",
        "            self._docs,\n",
        "            metric='cosine',\n",
        "            normalization=(1, 0),\n",
        "            limit=1,\n",
        "        )"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "80eb2490-4444-4b10-89ae-c45a8ef97cb9",
      "metadata": {
        "id": "80eb2490-4444-4b10-89ae-c45a8ef97cb9"
      },
      "source": [
        "`MyIndexer` exposes 2 endpoints: `index` and `search`. To perform indexing, you use docarray's\n",
        "[SQLite store](https://docarray.jina.ai/advanced/document-store/sqlite/).\n",
        "Indexing is a simple as adding the Documents to the `DocumentArray` with SQLite store.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>See Also:</b> Learn more about Document Stores: https://docarray.jina.ai/advanced/document-store/ </div>\n",
        "\n",
        "To perform the search operation, you use the method `match` which will return the top match for the query Documents using\n",
        "the cosine similarity.\n",
        "\n",
        "<div class=\"alert alert-block alert-info\">\n",
        "<b>See Also:</b> '.match()' is a method of DocumentArray. Learn more about it in the DocArray documentation: https://docarray.jina.ai/fundamentals/documentarray/matching/ </div>\n",
        "\n",
        "Now you can modify your app to use the real Executors:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "efe8ebd5-0960-4ccc-91ac-6deb96dae538",
      "metadata": {
        "id": "efe8ebd5-0960-4ccc-91ac-6deb96dae538"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "import webbrowser\n",
        "from jina import Flow\n",
        "from jina.logging.predefined import default_logger\n",
        "from docarray.document.generators import from_csv\n",
        "\n",
        "\n",
        "def tutorial(port_expose):\n",
        "    flow = (\n",
        "        Flow(cors=True, protocol='http', port_expose=port_expose)\n",
        "            .add(name='MyTransformer', uses=MyTransformer)\n",
        "            .add(name='MyIndexer', uses=MyIndexer, uses_metas={'workspace': os.path.abspath('')})\n",
        "    )\n",
        "    with flow:\n",
        "        flow.index(from_csv('dataset.csv', field_resolver={'question': 'text'}))\n",
        "        \n",
        "        url_html_path = 'file://' + os.path.abspath(\n",
        "            os.path.join(\n",
        "                os.path.abspath(''), 'static/index.html'\n",
        "            )\n",
        "        )\n",
        "        print(url_html_path)\n",
        "        try:\n",
        "            webbrowser.open(url_html_path, new=2)\n",
        "        except:\n",
        "            pass  # intentional pass, browser support isn't cross-platform\n",
        "        finally:\n",
        "            default_logger.success(\n",
        "                f'You should see a demo page opened in your browser, '\n",
        "                f'if not, you may open {url_html_path} manually'\n",
        "            )\n",
        "        flow.block()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "95a7cb4b-7a76-42ec-9131-e839a312f7d3",
      "metadata": {
        "id": "95a7cb4b-7a76-42ec-9131-e839a312f7d3"
      },
      "source": [
        "And finally, run it:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "a94218c8-38f5-455f-b642-119e582c365b",
      "metadata": {
        "id": "a94218c8-38f5-455f-b642-119e582c365b"
      },
      "outputs": [],
      "source": [
        "tutorial(8080)"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.8.10"
    },
    "colab": {
      "name": "chatbot.ipynb",
      "provenance": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}